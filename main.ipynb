{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MNIST data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('X_train shape', X_train.shape, 'X_test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing randomly some images in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "plt.figure(figsize = (12,5))\n",
    "for i in range(8):\n",
    "  ind = random.randint(0, len(X_train))\n",
    "  plt.subplot(240+1+i)\n",
    "  plt.imshow(X_train[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data:\n",
    "\n",
    "This task includes the following steps:\n",
    "\n",
    "Reshape images into the required size of Keras\n",
    "Convert integer values into float values\n",
    "Normalize data\n",
    "One-hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def preprocess_data(X_train, y_train, X_test, y_test):\n",
    "  # reshape images to the required size of Keras\n",
    "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "  \n",
    "  # convert image values from integers to floats\n",
    "  X_train = X_train.astype('float32')\n",
    "  X_test = X_test.astype('float32')\n",
    "  \n",
    "  # normalization\n",
    "  X_train = X_train/255.0\n",
    "  X_test_norm = X_test/255.0\n",
    "  \n",
    "  # One-hot encoding label \n",
    "  y_train = to_categorical(y_train)\n",
    "  y_test = to_categorical(y_test)\n",
    "  \n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "# (X_train, y_train, X_test, y_test) = preprocess_data(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building LeNet5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "# metrics \n",
    "from keras.metrics import categorical_crossentropy\n",
    "# optimization method\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def LeNet():\n",
    "  model = Sequential()\n",
    "  \n",
    "  # Convolutional layer  \n",
    "  model.add(Conv2D(filters = 6, kernel_size = (5,5), padding = 'same', \n",
    "                   activation = 'relu', input_shape = (28,28,1)))\n",
    "  \n",
    "  # Max-pooing layer with pooling window size is 2x2\n",
    "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "  \n",
    "  # Convolutional layer \n",
    "  model.add(Conv2D(filters = 16, kernel_size = (5,5), activation = 'relu'))\n",
    "  \n",
    "  # Max-pooling layer \n",
    "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "  \n",
    "  # Flatten layer \n",
    "  model.add(Flatten())\n",
    "  \n",
    "  # The first fully connected layer \n",
    "  model.add(Dense(120, activation = 'relu'))\n",
    "  \n",
    "  # The output layer  \n",
    "  model.add(Dense(10, activation = 'softmax'))\n",
    "  \n",
    "  # compile the model with a loss function, a metric and an optimizer function\n",
    "  # In this case, the loss function is categorical crossentropy, \n",
    "  # we use Stochastic Gradient Descent (SGD) method with learning rate lr = 0.01 \n",
    "  # to optimize the loss function\n",
    "  # metric: accuracy \n",
    "  \n",
    "  opt = SGD(learning_rate = 0.01)\n",
    "  model.compile(loss = categorical_crossentropy, \n",
    "                optimizer = opt, \n",
    "                metrics = ['accuracy']) \n",
    "                \n",
    "  return model\n",
    "\n",
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training LeNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_history(history):\n",
    "  plt.figure(figsize = (10,6))\n",
    "  plt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
    "  plt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n",
    "  plt.legend()\n",
    "  plt.title('Accuracy')\n",
    "  plt.show()\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs = 50, batch_size = 128):\n",
    "  # Rescaling all training and testing data\n",
    "  X_train, y_train, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)\n",
    "  # Fitting the model on the training set\n",
    "  history = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, \n",
    "                      steps_per_epoch = X_train.shape[0]//batch_size, \n",
    "                      validation_data = (X_test, y_test), \n",
    "                      validation_steps = X_test.shape[0]//batch_size, verbose = 1)\n",
    "  # evaluating the model\n",
    "  _, acc = model.evaluate(X_test, y_test, verbose = 1)\n",
    "  print('%.3f' % (acc * 100.0))\n",
    "  summary_history(history)\n",
    "\n",
    "train_model(model, X_train, y_train, X_test, y_test, 50, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "save_path = f'/content/drive/MyDrive/Colab Notebooks/Colab Folder/model.keras'\n",
    "model.save(filepath=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as models\n",
    "save_path = f'/content/drive/MyDrive/Colab Notebooks/Colab Folder/model.keras'\n",
    "model = models.load_model(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# predict labels for the test set\n",
    "y_test_pred = []\n",
    "for i in range(len(X_test)):\n",
    "  img = X_test[i]\n",
    "  cv2_imshow(img)\n",
    "  img = img.reshape(1,28,28,1)\n",
    "  img = img.astype('float32')\n",
    "  img = img/255.0\n",
    "  # one-hot vector output\n",
    "  vec_p = model.predict(img)\n",
    "  # determine the label corresponding to vector vec_p\n",
    "  y_p = np.argmax(vec_p)\n",
    "  y_test_pred.append(y_p)\n",
    "  print(f'Predicted Label: {y_p}, Actual Value: {y_test[i]}')\n",
    "  \n",
    "# convert y_test_pred from list to array\n",
    "y_test_pred = np.asarray(y_test_pred)\n",
    "save_path = f'/content/drive/MyDrive/Colab Notebooks/Colab Folder/predictions.csv'\n",
    "np.savetxt(save_path, y_test_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow # Import for displaying images in Colab\n",
    "\n",
    "\n",
    "# predict labels for the test set\n",
    "for i in np.random.choice(np.arange(0, len(X_test)), size=(10,)):\n",
    "  img = X_test[i]\n",
    "  cv2_imshow(img)\n",
    "  img = img.reshape(1,28,28,1)\n",
    "  img = img.astype('float32')\n",
    "  img = img/255.0\n",
    "  # one-hot vector output\n",
    "  vec_p = model.predict(img)\n",
    "  # determine the label corresponding to vector vec_p\n",
    "  y_p = np.argmax(vec_p)\n",
    "  print(f'Predicted Label: {y_p}, Actual Value: {y_test[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import loadtxt\n",
    "import seaborn as sns \n",
    "\n",
    "# load predictions\n",
    "save_path = f'/content/drive/MyDrive/Colab Notebooks/Colab Folder/predictions.csv'\n",
    "y_test_pred = loadtxt(save_path, delimiter=',')\n",
    "\n",
    "con_mat = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.heatmap(con_mat, linewidths = 0.1, cmap = 'Greens', linecolor = 'gray', \n",
    "            fmt = '.1f', annot = True)\n",
    "plt.xlabel('Predicted classes', fontsize = 20)\n",
    "plt.ylabel('True classes', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise some numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all categories\n",
    "cates = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "for i in np.arange(8):\n",
    "  ind = random.randint(0,len(X_test))\n",
    "  img = X_test[ind]\n",
    "  img = img.reshape(1,28,28,1)\n",
    "  img = img.astype('float32')\n",
    "  img = img/255.0\n",
    "  v_p = model.predict(img)\n",
    "  plt.subplot(240+1+i)\n",
    "  plt.imshow(X_test[ind])\n",
    "  plt.title(cates[v_p[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, draw the model so we can talk about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "# Plot the model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the plot in Colab\n",
    "Image(retina=True, filename='model.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
